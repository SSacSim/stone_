{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\windowadmin4.WIN-B8QF2DSGDAG\\anaconda3\\envs\\dacon\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "# 이미지 증량 및 처리를 위한 라이브러리 ( albumentations )\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "# sklearn \n",
    "from sklearn.model_selection import train_test_split # train test Split \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score # f1 score \n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':448,\n",
    "    'EPOCHS':30,\n",
    "    'LEARNING_RATE':1e-5,\n",
    "    'BATCH_SIZE':4,\n",
    "    'SEED':1042\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_list = glob.glob('../data/train/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['img_path', 'rock_type'])\n",
    "df['img_path'] = all_img_list\n",
    "df['rock_type'] = df['img_path'].apply(lambda x : str(x).split('\\\\')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rock_type\n",
       "Granite           92923\n",
       "Mud_Sandstone     89467\n",
       "Gneiss            73914\n",
       "Andesite          43802\n",
       "Weathered_Rock    37169\n",
       "Basalt            26810\n",
       "Etc               15935\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rock_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(300 , random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, df['rock_type'], test_size=0.3, stratify=df['rock_type'], random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rock_type\n",
       "Granite           0.244521\n",
       "Mud_Sandstone     0.235427\n",
       "Gneiss            0.194500\n",
       "Andesite          0.115262\n",
       "Weathered_Rock    0.097808\n",
       "Basalt            0.070549\n",
       "Etc               0.041932\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rock_type\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to encoded value mapping: {'Andesite': 0, 'Basalt': 1, 'Etc': 2, 'Gneiss': 3, 'Granite': 4, 'Mud_Sandstone': 5, 'Weathered_Rock': 6}\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train['rock_type'] = le.fit_transform(train['rock_type'])\n",
    "val['rock_type'] = le.transform(val['rock_type'])\n",
    "\n",
    "# 각 라벨에 대한 인코딩 값 확인\n",
    "label_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "print(\"Label to encoded value mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadSquare(ImageOnlyTransform):\n",
    "    def __init__(self, border_mode=0, value=0, always_apply=False, p=1.0):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.border_mode = border_mode\n",
    "        self.value = value\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        h, w, c = image.shape\n",
    "        max_dim = max(h, w)\n",
    "        pad_h = max_dim - h\n",
    "        pad_w = max_dim - w\n",
    "        top = pad_h // 2\n",
    "        bottom = pad_h - top\n",
    "        left = pad_w // 2\n",
    "        right = pad_w - left\n",
    "        image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=self.value)\n",
    "        return image\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"border_mode\", \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'eva02_large_patch14_448.mim_m38m_ft_in22k_in1k'\n",
    "model = timm.create_model(model_name, pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import resolve_data_config\n",
    "config = resolve_data_config({}, model=model)\n",
    "CFG['mean'] =config['mean']\n",
    "CFG['std'] = config['std']\n",
    "# CFG.interpolation = config.interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    # PadSquare(value=(0, 0, 0)),\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE'] ,interpolation=cv2.INTER_CUBIC),\n",
    "    A.Affine(rotate=(-360,360),shear={\"x\": (-10, 10), \"y\": (-10, 10)}, border_mode = 1,p = 1 ),\n",
    "    A.GridDistortion(num_steps=5, distort_limit=0.2, p= 0.5),\n",
    "    A.Morphological(scale = (1,3), operation=\"erosion\",p = 0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p = 0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.CoarseDropout(num_holes_range=(3, 5) , p = 0.5 ),\n",
    "    A.RandomResizedCrop( size = (CFG['IMG_SIZE'], CFG['IMG_SIZE']), scale = (0.7,1),ratio=(0.75, 1.33), p=0.5),  # Random zoom effect\n",
    "    A.Normalize(mean=CFG['mean'], std=CFG['std']),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    # PadSquare(value=(0, 0, 0)),\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE'] ,interpolation=cv2.INTER_CUBIC),\n",
    "    A.Normalize(mean=CFG['mean'], std=CFG['std']),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train['img_path'].values, train['rock_type'].values, train_transform)\n",
    "# train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=4,pin_memory=True,prefetch_factor=2)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['rock_type'].values, test_transform)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4,pin_memory=True,prefetch_factor=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device , patience = 5 ):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    early_stop_counter = 0\n",
    "    best_model = None\n",
    "    save_path = f\"best_model_{model_name}.pth\"\n",
    "\n",
    "\n",
    "    for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "\n",
    "        for imgs, labels in tqdm(iter(train_loader), desc=f\"Epoch {epoch}\"):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device, epoch)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch}], Train Loss: {_train_loss:.5f}, Val Loss: {_val_loss:.5f}, Val Macro F1: {_val_score:.5f}')\n",
    "        torch.save(model.state_dict(), f\"{epoch}_{model_name}_{_val_loss:.5f}.pth\")\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "\n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "\n",
    "            # 모델 가중치 저장\n",
    "            torch.save(model.state_dict(), f\"best_{epoch}_{model_name}_{_val_loss:.5f}.pth\")\n",
    "            print(f\"Best model saved (epoch {epoch}, F1={_val_score:.4f}) → {save_path}\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            print(f\"No improvement for {early_stop_counter} epoch(s)\")\n",
    "\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device , epoch):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='macro')\n",
    "\n",
    "        # 예측 결과와 실제 값을 pandas DataFrame으로 생성\n",
    "        # Calculate F1 score for each label\n",
    "        f1_per_class = f1_score(true_labels, preds, average=None)\n",
    "\n",
    "        # Create a DataFrame for label-wise F1 scores\n",
    "        f1_df = pd.DataFrame({\n",
    "            'Label': le.classes_,\n",
    "            'F1 Score': f1_per_class\n",
    "        })\n",
    "\n",
    "        # Save the F1 scores to a CSV file\n",
    "        f1_df.to_csv(f\"{epoch}_f1_scores_per_label.csv\", index=False)\n",
    "        print(f\"F1 scores per label saved to {epoch}_f1_scores_per_label.csv\")\n",
    "\n",
    "        # Save the validation results\n",
    "        results_df = pd.DataFrame({\n",
    "            'gt': true_labels,\n",
    "            'pred': preds\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(f\"validation_results_{epoch}.csv\", index=False)\n",
    "        print(f\"Validation results saved to validation_results_{epoch}.csv\")\n",
    "\n",
    "        # # CSV 파일로 저장\n",
    "        # results_df.to_csv(f\"validation_results_{epoch}.csv\", index=False)\n",
    "        # print(f\"Validation results saved to validation_results_{epoch}.csv\")\n",
    "        \n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name ,num_classes=len(le.classes_)):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True).to(device)\n",
    "        self.classifier = nn.Linear(1000, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 12/66504 [00:21<31:31:31,  1.71s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR\n",
    "model = BaseModel(model_name)\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"], weight_decay=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8)\n",
    "# scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=CFG['EPOCHS'], eta_min=1e-8)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')\n",
    "test[\"img_path\"] = test[\"img_path\"].apply(lambda x : \"../data/test/\"+x.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eva(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (rope): RotaryEmbeddingCat()\n",
       "  (blocks): ModuleList(\n",
       "    (0-23): 24 x EvaBlock(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): EvaAttention(\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): SwiGLU(\n",
       "        (fc1_g): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "        (fc1_x): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): Identity()\n",
       "  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #model load\n",
    "# load_model = timm.create_model(model_name, pretrained=False).to(device)\n",
    "# load_model.load_state_dict(torch.load(\"/mnt/sdb/sim/dacon/ipynb_files/best_model_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.pth\"))\n",
    "# load_model.eval()  # 평가 모드로 전환 (옵션)\n",
    "load_model = infer_model\n",
    "infer_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    preds = le.inverse_transform(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11876 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11876/11876 [48:42<00:00,  4.06it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(load_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('/mnt/sdb/sim/dacon/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['rock_type'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./5만_baseline_submit_eva02_448.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>rock_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>Mud_Sandstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>Mud_Sandstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>Mud_Sandstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>Granite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>Granite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95001</th>\n",
       "      <td>TEST_95001</td>\n",
       "      <td>Gneiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95002</th>\n",
       "      <td>TEST_95002</td>\n",
       "      <td>Gneiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95003</th>\n",
       "      <td>TEST_95003</td>\n",
       "      <td>Gneiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95004</th>\n",
       "      <td>TEST_95004</td>\n",
       "      <td>Gneiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95005</th>\n",
       "      <td>TEST_95005</td>\n",
       "      <td>Gneiss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95006 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      rock_type\n",
       "0      TEST_00000  Mud_Sandstone\n",
       "1      TEST_00001  Mud_Sandstone\n",
       "2      TEST_00002  Mud_Sandstone\n",
       "3      TEST_00003        Granite\n",
       "4      TEST_00004        Granite\n",
       "...           ...            ...\n",
       "95001  TEST_95001         Gneiss\n",
       "95002  TEST_95002         Gneiss\n",
       "95003  TEST_95003         Gneiss\n",
       "95004  TEST_95004         Gneiss\n",
       "95005  TEST_95005         Gneiss\n",
       "\n",
       "[95006 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation F1 Score Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# f1_scores_per_label.csv 파일을 읽기\n",
    "epoch = 1 \n",
    "f1_df = pd.read_csv(f\"{epoch}_f1_scores_per_label.csv\")\n",
    "\n",
    "# Plotting F1 scores for each label\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='F1 Score', y='Label', data=f1_df, palette='viridis')\n",
    "plt.title(\"F1 Score per Label\")\n",
    "plt.xlabel(\"F1 Score\")\n",
    "plt.ylabel(\"Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
