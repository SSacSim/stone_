{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/Anaconda_envs/dacon/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "# 이미지 증량 및 처리를 위한 라이브러리 ( albumentations )\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "# sklearn \n",
    "from sklearn.model_selection import train_test_split # train test Split \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score # f1 score \n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':448,\n",
    "    'EPOCHS':30,\n",
    "    'LEARNING_RATE':1e-5,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':1042\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_list = glob.glob('../data/train/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['img_path', 'rock_type'])\n",
    "df['img_path'] = all_img_list\n",
    "df['rock_type'] = df['img_path'].apply(lambda x : str(x).split('/')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETC 데이터 증량 \n",
    "df = pd.concat([df,df[df['rock_type' ] ==\"Etc\"]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rock_type\n",
       "Granite           92923\n",
       "Mud_Sandstone     89467\n",
       "Gneiss            73914\n",
       "Andesite          43802\n",
       "Weathered_Rock    37169\n",
       "Etc               31870\n",
       "Basalt            26810\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rock_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(50000 , random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, df['rock_type'], test_size=0.3, stratify=df['rock_type'], random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rock_type\n",
       "Granite           0.23510\n",
       "Mud_Sandstone     0.22570\n",
       "Gneiss            0.18912\n",
       "Andesite          0.10816\n",
       "Weathered_Rock    0.09172\n",
       "Etc               0.08170\n",
       "Basalt            0.06850\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rock_type\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to encoded value mapping: {'Andesite': 0, 'Basalt': 1, 'Etc': 2, 'Gneiss': 3, 'Granite': 4, 'Mud_Sandstone': 5, 'Weathered_Rock': 6}\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train['rock_type'] = le.fit_transform(train['rock_type'])\n",
    "val['rock_type'] = le.transform(val['rock_type'])\n",
    "\n",
    "# 각 라벨에 대한 인코딩 값 확인\n",
    "label_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "print(\"Label to encoded value mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadSquare(ImageOnlyTransform):\n",
    "    def __init__(self, border_mode=0, value=0, always_apply=False, p=1.0):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.border_mode = border_mode\n",
    "        self.value = value\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        h, w, c = image.shape\n",
    "        max_dim = max(h, w)\n",
    "        pad_h = max_dim - h\n",
    "        pad_w = max_dim - w\n",
    "        top = pad_h // 2\n",
    "        bottom = pad_h - top\n",
    "        left = pad_w // 2\n",
    "        right = pad_w - left\n",
    "        image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=self.value)\n",
    "        return image\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"border_mode\", \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'eva02_large_patch14_448.mim_m38m_ft_in22k_in1k'\n",
    "model = timm.create_model(model_name, pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import resolve_data_config\n",
    "config = resolve_data_config({}, model=model)\n",
    "CFG['mean'] =config['mean']\n",
    "CFG['std'] = config['std']\n",
    "# CFG.interpolation = config.interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    # PadSquare(value=(0, 0, 0)),\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE'] ,interpolation=cv2.INTER_CUBIC),\n",
    "    A.Affine(rotate=(-360,360),shear={\"x\": (-10, 10), \"y\": (-10, 10)}, border_mode = 1,p = 1 ),\n",
    "    A.GridDistortion(num_steps=5, distort_limit=0.2, p= 0.5),\n",
    "    A.Morphological(scale = (1,3), operation=\"erosion\",p = 0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p = 0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.CoarseDropout(num_holes_range=(3, 5) , p = 0.5 ),\n",
    "    A.RandomResizedCrop( size = (CFG['IMG_SIZE'], CFG['IMG_SIZE']), scale = (0.7,1),ratio=(0.75, 1.33), p=0.5),  # Random zoom effect\n",
    "    A.Normalize(mean=CFG['mean'], std=CFG['std']),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    # PadSquare(value=(0, 0, 0)),\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE'] ,interpolation=cv2.INTER_CUBIC),\n",
    "    A.Normalize(mean=CFG['mean'], std=CFG['std']),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train['img_path'].values, train['rock_type'].values, train_transform)\n",
    "# train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=4,pin_memory=True,prefetch_factor=2)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['rock_type'].values, test_transform)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=4,pin_memory=True,prefetch_factor=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device , patience = 5 ):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    early_stop_counter = 0\n",
    "    best_model = None\n",
    "    save_path = f\"best_model_{model_name}.pth\"\n",
    "\n",
    "\n",
    "    for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "\n",
    "        for imgs, labels in tqdm(iter(train_loader), desc=f\"Epoch {epoch}\"):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device, epoch)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch}], Train Loss: {_train_loss:.5f}, Val Loss: {_val_loss:.5f}, Val Macro F1: {_val_score:.5f}')\n",
    "        torch.save(model.state_dict(), f\"1_{epoch}_{model_name}_{_val_loss:.5f}.pth\")\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "\n",
    "        if best_score < _val_score:\n",
    "            early_stop_counter = 0\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "\n",
    "            # 모델 가중치 저장\n",
    "            torch.save(model.state_dict(), f\"1_best_{epoch}_{model_name}_{_val_loss:.5f}.pth\")\n",
    "            print(f\"Best model saved (epoch {epoch}, F1={_val_score:.4f}) → {save_path}\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            print(f\"No improvement for {early_stop_counter} epoch(s)\")\n",
    "\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device , epoch):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='macro')\n",
    "\n",
    "        # 예측 결과와 실제 값을 pandas DataFrame으로 생성\n",
    "        # Calculate F1 score for each label\n",
    "        f1_per_class = f1_score(true_labels, preds, average=None)\n",
    "\n",
    "        # Create a DataFrame for label-wise F1 scores\n",
    "        f1_df = pd.DataFrame({\n",
    "            'Label': le.classes_,\n",
    "            'F1 Score': f1_per_class\n",
    "        })\n",
    "\n",
    "        # Save the F1 scores to a CSV file\n",
    "        f1_df.to_csv(f\"{epoch}_f1_scores_per_label_1.csv\", index=False)\n",
    "        print(f\"F1 scores per label saved to {epoch}_f1_scores_per_label.csv\")\n",
    "\n",
    "        # Save the validation results\n",
    "        results_df = pd.DataFrame({\n",
    "            'gt': true_labels,\n",
    "            'pred': preds\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(f\"validation_results_1_{epoch}.csv\", index=False)\n",
    "        print(f\"Validation results saved to validation_results_{epoch}.csv\")\n",
    "\n",
    "        # # CSV 파일로 저장\n",
    "        # results_df.to_csv(f\"validation_results_{epoch}.csv\", index=False)\n",
    "        # print(f\"Validation results saved to validation_results_{epoch}.csv\")\n",
    "        \n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name ,num_classes=len(le.classes_)):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True).to(device)\n",
    "        self.classifier = nn.Linear(1000, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4375/4375 [1:02:22<00:00,  1.17it/s]\n",
      "100%|██████████| 1875/1875 [10:47<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 1_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_1.csv\n",
      "Epoch [1], Train Loss: 0.73012, Val Loss: 0.57586, Val Macro F1: 0.76523\n",
      "Best model saved (epoch 1, F1=0.7652) → best_model_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 4375/4375 [51:17<00:00,  1.42it/s]\n",
      "100%|██████████| 1875/1875 [07:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 2_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_2.csv\n",
      "Epoch [2], Train Loss: 0.54176, Val Loss: 0.51587, Val Macro F1: 0.78426\n",
      "Best model saved (epoch 2, F1=0.7843) → best_model_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4375/4375 [51:18<00:00,  1.42it/s]\n",
      "100%|██████████| 1875/1875 [07:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 3_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_3.csv\n",
      "Epoch [3], Train Loss: 0.44931, Val Loss: 0.51448, Val Macro F1: 0.80545\n",
      "Best model saved (epoch 3, F1=0.8055) → best_model_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4375/4375 [51:19<00:00,  1.42it/s]\n",
      "100%|██████████| 1875/1875 [07:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 4_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_4.csv\n",
      "Epoch [4], Train Loss: 0.36091, Val Loss: 0.45141, Val Macro F1: 0.81909\n",
      "Best model saved (epoch 4, F1=0.8191) → best_model_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 4375/4375 [51:19<00:00,  1.42it/s]\n",
      "100%|██████████| 1875/1875 [07:01<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 5_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_5.csv\n",
      "Epoch [5], Train Loss: 0.29291, Val Loss: 0.41403, Val Macro F1: 0.84303\n",
      "Best model saved (epoch 5, F1=0.8430) → best_model_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4375/4375 [51:20<00:00,  1.42it/s]\n",
      "100%|██████████| 1875/1875 [07:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 6_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_6.csv\n",
      "Epoch [6], Train Loss: 0.22514, Val Loss: 0.49438, Val Macro F1: 0.82149\n",
      "No improvement for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 4375/4375 [51:20<00:00,  1.42it/s]\n",
      "100%|██████████| 1875/1875 [07:00<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 7_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_7.csv\n",
      "Epoch [7], Train Loss: 0.17704, Val Loss: 0.46409, Val Macro F1: 0.84124\n",
      "No improvement for 2 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 4375/4375 [51:20<00:00,  1.42it/s]\n",
      "100%|██████████| 1875/1875 [07:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 8_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_8.csv\n",
      "Epoch [8], Train Loss: 0.14627, Val Loss: 0.47883, Val Macro F1: 0.84488\n",
      "Best model saved (epoch 8, F1=0.8449) → best_model_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4375/4375 [51:24<00:00,  1.42it/s]\n",
      "100%|██████████| 1875/1875 [07:01<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 9_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_9.csv\n",
      "Epoch [9], Train Loss: 0.12682, Val Loss: 0.52542, Val Macro F1: 0.84109\n",
      "No improvement for 3 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 4375/4375 [51:41<00:00,  1.41it/s]\n",
      "100%|██████████| 1875/1875 [07:21<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 10_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_10.csv\n",
      "Epoch [10], Train Loss: 0.10083, Val Loss: 0.53524, Val Macro F1: 0.83999\n",
      "No improvement for 4 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 4375/4375 [51:46<00:00,  1.41it/s]\n",
      "100%|██████████| 1875/1875 [07:09<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 11_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_11.csv\n",
      "Epoch [11], Train Loss: 0.10034, Val Loss: 0.51605, Val Macro F1: 0.84611\n",
      "Best model saved (epoch 11, F1=0.8461) → best_model_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 4375/4375 [52:11<00:00,  1.40it/s]\n",
      "100%|██████████| 1875/1875 [07:11<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores per label saved to 12_f1_scores_per_label.csv\n",
      "Validation results saved to validation_results_12.csv\n",
      "Epoch [12], Train Loss: 0.08771, Val Loss: 0.60776, Val Macro F1: 0.83512\n",
      "No improvement for 5 epoch(s)\n",
      "Early stopping triggered at epoch 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR\n",
    "model = BaseModel(model_name)\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"], weight_decay=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8)\n",
    "# scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=CFG['EPOCHS'], eta_min=1e-8)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')\n",
    "test[\"img_path\"] = test[\"img_path\"].apply(lambda x : \"../data/test/\"+x.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (backbone): Eva(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (rope): RotaryEmbeddingCat()\n",
       "    (blocks): ModuleList(\n",
       "      (0-23): 24 x EvaBlock(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): EvaAttention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SwiGLU(\n",
       "          (fc1_g): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "          (fc1_x): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "          (act): SiLU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "          (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): Identity()\n",
       "    (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1000, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #model load\n",
    "# load_model = timm.create_model(model_name, pretrained=False).to(device)\n",
    "# load_model.load_state_dict(torch.load(\"/mnt/sdb/sim/dacon/ipynb_files/best_model_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.pth\"))\n",
    "# load_model.eval()  # 평가 모드로 전환 (옵션)\n",
    "load_model = infer_model\n",
    "infer_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    logits = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            logits.append(pred)\n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    preds = le.inverse_transform(preds)\n",
    "    return preds , logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11876/11876 [1:06:12<00:00,  2.99it/s]\n"
     ]
    }
   ],
   "source": [
    "preds , logits = inference(load_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('/mnt/hdd1/sim/dacon/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['rock_type'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./1_30epoch_5만_baseline_submit_eva02_448.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation F1 Score Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# f1_scores_per_label.csv 파일을 읽기\n",
    "epoch = 1 \n",
    "f1_df = pd.read_csv(f\"{epoch}_f1_scores_per_label.csv\")\n",
    "\n",
    "# Plotting F1 scores for each label\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='F1 Score', y='Label', data=f1_df, palette='viridis')\n",
    "plt.title(\"F1 Score per Label\")\n",
    "plt.xlabel(\"F1 Score\")\n",
    "plt.ylabel(\"Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
